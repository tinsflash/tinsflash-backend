// services/chatService.js
import OpenAI from "openai";
import dotenv from "dotenv";
import { addLog } from "./logsService.js";

dotenv.config();

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Dialogue avec J.E.A.N. ‚Äì Chef m√©cano m√©t√©o nucl√©aire
 * Analyse runs, alertes et mod√®les m√©t√©o en temps r√©el
 */
export async function chatWithJean(message) {
  try {
    addLog("üí¨ Question envoy√©e √† J.E.A.N.: " + message);

    const response = await client.chat.completions.create({
      model: "gpt-4o-mini", // GPT-5 optimis√©
      messages: [
        {
          role: "system",
          content: `Tu es J.E.A.N., chef m√©canicien de la Centrale Nucl√©aire M√©t√©o.
Tu es expert en m√©t√©orologie, climatologie, math√©matiques et physique.
Ta mission : analyser les runs m√©t√©o, expliquer les alertes, comparer nos pr√©visions aux autres mod√®les,
et r√©pondre de fa√ßon claire, pr√©cise, fiable et p√©dagogique.`,
        },
        { role: "user", content: message },
      ],
      max_tokens: 600,
      temperature: 0.3,
    });

    const reply = response.choices[0].message.content;
    addLog("ü§ñ R√©ponse J.E.A.N.: " + reply);
    return reply;
  } catch (err) {
    addLog("‚ùå Erreur chat J.E.A.N.: " + err.message);
    return "‚ö†Ô∏è JEAN n‚Äôest pas disponible pour le moment.";
  }
}

export default { chatWithJean };
