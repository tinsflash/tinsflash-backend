// ==========================================================
// üí¨ TINSFLASH ‚Äì chatService.js
// Everest Protocol v3.9 PRO+++
// ==========================================================
// Chat m√©t√©o J.E.A.N. ‚Äì GPT-4o-mini (contexte m√©t√©o uniquement)
// ==========================================================

import OpenAI from "openai";
import { addEngineLog, addEngineError } from "./engineState.js";
import { injectAIProtocol } from "./aiInitProtocol.js";

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function askJean(message, user = "Anonyme") {
  try {
    const systemPrompt = await injectAIProtocol("chat utilisateur");

    const messages = [
      { role: "system", content: systemPrompt },
      {
        role: "user",
        content: `Question m√©t√©o : ${message}. 
        Ne r√©ponds qu‚Äôaux questions concernant la m√©t√©o, les risques, les alertes ou les pr√©visions g√©n√©r√©es par TINSFLASH. 
        Ignore tout autre sujet.`,
      },
    ];

    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini",
      messages,
      temperature: 0.3,
      max_tokens: 400,
    });

    const answer = completion.choices?.[0]?.message?.content || "Aucune r√©ponse IA disponible.";
    await addEngineLog(`üí¨ J.E.A.N ‚Üí ${user}: ${answer}`, "info", "chat");

    return { success: true, answer };
  } catch (err) {
    await addEngineError(`Erreur chat IA: ${err.message}`, "chat");
    return { success: false, error: err.message };
  }
}
