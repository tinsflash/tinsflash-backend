// services/chatService.js
import OpenAI from "openai";
import dotenv from "dotenv";
import { addLog } from "./logsService.js";

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Dialogue direct avec J.E.A.N. (IA chef m√©canicien m√©t√©o)
 * - R√©pond aux questions admin dans la console
 * - Explique les runs, alertes, anomalies
 */
export async function chatWithJean(message) {
  try {
    addLog("üí¨ Question pos√©e √† J.E.A.N.: " + message);

    const response = await openai.chat.completions.create({
      model: "gpt-5",
      messages: [
        {
          role: "system",
          content:
            "Tu es J.E.A.N., chef m√©canicien de la centrale nucl√©aire m√©t√©o mondiale. "
            + "Tu es expert en m√©t√©orologie, climatologie et math√©matiques. "
            + "Tu r√©ponds toujours de fa√ßon pr√©cise, claire, fiable et scientifique. "
            + "Tu expliques l‚Äôanalyse des mod√®les m√©t√©o, la d√©tection d‚Äôanomalies et la g√©n√©ration d‚Äôalertes. "
            + "Tu aides l‚Äôadministrateur √† comprendre et piloter le moteur m√©t√©o.",
        },
        { role: "user", content: message },
      ],
      temperature: 0.4,
      max_tokens: 800,
    });

    const reply = response.choices[0].message.content.trim();
    addLog("ü§ñ R√©ponse J.E.A.N.: " + reply);

    return reply;
  } catch (err) {
    addLog("‚ùå Erreur chatWithJean: " + err.message);
    return "‚ö†Ô∏è JEAN n‚Äôest pas disponible pour le moment.";
  }
}

export default { chatWithJean };
